name: test opencosmo
on: workflow_call
jobs:
  get-test-data:
    runs-on: ubuntu-latest
    steps:
      - name: Setup AWS CLI
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.TEST_DATA_ACCESS_KEY }}
          aws-secret-access-key: ${{ secrets.TEST_DATA_SECRET_KEY }}
          aws-region: us-west-2
      - name: check if cache exists
        id: check-cache
        uses: actions/cache@v4
        with:
          path: test_data.tar.gz
          key: test-data
          lookup-only: true
          restore-keys: |
            test-data
      - name: Download test data 
        if: steps.check-cache.outputs.cache-hit != 'true'
        run: aws s3 cp s3://${{ secrets.TEST_DATA_BUCKET }}/test_data.tar.gz test_data.tar.gz
      - name: Cache test data
        if: steps.check-cache.outputs.cache-hit != 'true'
        id: cache-test-data
        uses: actions/cache@v4
        with:
          path: test_data.tar.gz
          key: test-data
          enableCrossOsArchive: true
          
  run-tests:
    name: Run tests
    runs-on: ${{ matrix.os }}
    needs: [get-test-data]
    strategy:
      matrix:
        os: [ubuntu-latest, macos-latest]
        python-version: ['3.11', '3.12', '3.13']
    defaults:
      run:
        shell: bash
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      - name: get test data
        uses: actions/cache@v4
        with:
          path: test_data.tar.gz
          key: test-data
          enableCrossOsArchive: true
      - name: Unpack test data
        run: |
          mkdir -p test_data
          tar -xzf test_data.tar.gz -C test_data
      - name: install uv
        uses: astral-sh/setup-uv@v6
        with:
          version: "0.8.2"
      - name: install python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python-version }}
      - name: Install dependencies
        run: uv sync --all-extras

      - name: install analysis dependencies
        run: uv run opencosmo install haloviz --dev
      - name: Run tests with pytest
        run: |
          uv run pytest --ignore=test/parallel

  run-parallel-tests:
    runs-on: ubuntu-latest
    needs: [get-test-data]
    strategy:
      matrix:
        python-version: ['3.11', '3.12', '3.13']
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      - name: setup mpi
        uses: mpi4py/setup-mpi@v1
        with:
          mpi: openmpi

      - name: install parallel hdf5
        run: sudo apt install -y libhdf5-mpi-dev
      - name: get test data
        uses: actions/cache@v4
        with:
          path: test_data.tar.gz
          key: test-data
          enableCrossOsArchive: true
      - name: Unpack test data
        run: |
          mkdir -p test_data
          tar -xzf test_data.tar.gz -C test_data
      - name: install uv
        uses: astral-sh/setup-uv@v6
        with:
          version: "0.8.2"
      - name: install python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python-version }}

      - name: install project
        run: uv sync --group mpi --group test-mpi
      - name: build hdf5 in paralell
        run: |
          CC="mpicc" HDF5_MPI="ON" uv pip install --reinstall --no-binary=h5py h5py
      - name: get number of cores
        run: echo "Running on $(nproc) cores"
      - name: Run tests with pytest
        run: |
          uv run mpiexec --timeout 120 --use-hwthread-cpus -n 4 pytest -m parallel test/parallel/test_lc_mpi.py::test_write_some_missing -x -s
